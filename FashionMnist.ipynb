{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Fashion Mnist\nFashion MNist es un dataset que contiene imágenes de ropa con fines académicos de aprender a crear un sistema de clasificación."},{"metadata":{},"cell_type":"markdown","source":"## Redes Neuronales Completamente Conectadas\nEste es el sistema que usaremos para resolver el problema."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando las librerías\nfrom fashion_mnist_master.utils.mnist_reader import load_mnist\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.optimize as op\nimport itertools","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Importando la data\nX_train, y_train = load_mnist('fashion_mnist_master/data/fashion', kind='train')\nX_test, y_test = load_mnist('fashion_mnist_master/data/fashion', kind='t10k')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Gráficando un elemento \nX = np.array(X_train[1])\nX = X.reshape((28, 28))\n## Poniéndolo en blanco y negro\nfig, ax = plt.subplots()\nax.imshow(X, interpolation='nearest', cmap='gray')\nplt.show()","execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"Tras ver la data por anticipado, se puede notar que existen valores entre 0 y 255 para identificar la intensidad de color de bits en la imagen. Debido a que los números están demasiado grandes. Por éso se procede a aplicarles una reducción a través de la variable _chiquitolina_. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Transformación de X_train\nchiquitolina = (1/255) # Para achiquitar los valores\nX_train = X_train * (chiquitolina)\nX_train = X_train.astype(np.float32)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(0) # Semilla de aleatoriedad constante","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## X_train tiene la siguiente forma\n### (observaciones, atributos)\n### Cada elemento del array es una observación. \n### Según mi documento oficial juandieguístico tiene la forma n*m\nL = 6 # Capas desde la X hasta la Y\n### One-hot enconding para Y\ny_train_one_hot = np.zeros((y_train.size, y_train.max()+1))\ny_train_one_hot[np.arange(y_train.size),y_train] = 1","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Funciones propias de la Red Neuronal y capas de activación\nLas funciones que servirán como parámetros para la aplicación de _optimize_."},{"metadata":{"trusted":true},"cell_type":"code","source":"## FUNCIONES IMPORTANTES\ndef funcion_sigmoide(x, tetas):\n    \"\"\"Realiza la función sigmoide\n        para cualquier parámetro teta\n    \"\"\"\n    return np.power((1 + np.exp(-1 * np.dot(x, tetas.T)) ), -1).astype(np.float16)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def funcion_costo(tetas, figuras, x, y):\n    \"\"\"Realiza la función de costo\n        para cualquier parámetro teta\n    \"\"\"\n    tetas = deschatar_thetas(tetas, figuras)\n    neuronas = forward_propagation(tetas, x) # Multiplicación de tetas\n    return np.sum(np.multiply(y, np.log( neuronas[L-1] )) + np.multiply((1-y), np.log(1 - neuronas[L-1]))  ) / -len(y)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def precision(y_pred, y):\n    \"\"\"Calcula la precisión del modelo con base\n        a los valores reales y predichos de Y \n    \"\"\"\n    enconding = 0\n    for i in range(len(y_pred)):\n        valorMax = max(y_pred[i])\n        valor = np.where(y_pred[i] == valorMax)\n        if(valor == y[i]):\n            enconding += 1 \n        \n    return enconding / len(y)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Variables de uso general para la red neuronal\nAquí irán las neuronas, tamaño del modelo, constantes multiplicadoras y capa de _bias_."},{"metadata":{"trusted":true},"cell_type":"code","source":"thetas = []\n#### Cada elemento contiene un arreglo de thetas. \n####      Para el primero son c*m según el documento juandieguístico.\n#### Después serán 5*5 y el último será 10*6\nthetas1 = np.random.rand(5, 785) # X a capa1\nthetas2 = np.random.rand(5, 6) # capa1 a 2\nthetas3 = np.random.rand(5, 6) # capa2 a 3\nthetas4 = np.random.rand(5, 6) # capa3 a 4\nthetas5 = np.random.rand(10, 6) # capa4 a resultado\n## agregando thetas\nthetas.append(thetas1)\nthetas.append(thetas2)\nthetas.append(thetas3)\nthetas.append(thetas4)\nthetas.append(thetas5)\n\nfiguras = [(5, 785), (5, 6), (5, 6), (5, 6), (10, 6)]\n\nunos = np.ones((len(X_train), 1)).astype(np.float32) ## agregar columna de unos","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Funciones de transformación de thetas para Scipy optimize\nLos multiplicadores deben de entregarse en un arreglo plano, por lo que hay funciones para aplanarlo y desaplanarlo."},{"metadata":{"trusted":true},"cell_type":"code","source":"def achatar_thetas(tetas):\n    achatadas = np.array([])\n    for i in tetas:\n        achatadas = np.append(achatadas, i.flatten())\n    achatadas.flatten()\n    return achatadas\n\ndef deschatar_thetas(tetas, figura):\n    deschatadas = []\n    inicio = 0\n    fin = 0\n    for i in figura:\n        fin = inicio + i[1]*i[0]\n        deschatadas.append(np.array(tetas[inicio:fin]).reshape(i))\n        inicio = fin\n    return deschatadas","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Funciones NN"},{"metadata":{"trusted":true},"cell_type":"code","source":"def forward_propagation(tetas, x):\n    neuronas = [None] * L\n    neuronas[0] = x ## agregando la primera capa\n    for i in range(len(tetas)):\n        ###### La siguiente neurona\n        # print(i)\n        # print(neuronas[i].shape)\n        # print((np.append(neuronas[i], unos, axis=1)).shape)\n        # print(neuronas[i])\n        # capa_mas_bias = np.append(neuronas[i], unos, axis=1) # neurona actual más capa de unos (bias)\n        neuronas[i + 1] = funcion_sigmoide(\n            np.append(neuronas[i], unos, axis=1), tetas[i]) # Thetas actuales (ya incluyen la capa bias)\n    return neuronas","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def back_propagation(tetas, figuras, x, y):\n    tetas = deschatar_thetas(tetas, figuras)\n    # Back propagation\n    # Forward Propagation (Paso 2.2)\n    neuronas = forward_propagation(tetas, x)\n    # Paso 1 y 2.1\n    Deltas = [i * 0.0 for i in tetas]\n    deltas = [i * 0.0 for i in neuronas]\n    deltas[L - 1] = neuronas[L - 1] - y # Paso 2.3 del documento de Samuel Chávez\n    for l in reversed(range(0, L - 1)):\n        # Paso 2.4\n        deltas[l] = np.multiply(\n                np.dot(tetas[l].T[:-1], deltas[l + 1].T).T,\n                np.multiply(\n                    neuronas[l],\n                    (1 - neuronas[l])\n                    ))\n        \n        # Paso 2.5\n        Deltas[l] = Deltas[l] + np.dot(deltas[l + 1].T,\n                                       np.append(neuronas[l],\n                                                 unos, axis=1))\n        # Paso 3\n        Deltas[l] = Deltas[l] * (1/len(x))\n    return achatar_thetas(Deltas)","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Implementación con Optimize"},{"metadata":{"trusted":true},"cell_type":"code","source":"thetas = achatar_thetas(thetas)\nprint(thetas, thetas.shape)\ncosto = funcion_costo(thetas, figuras, X_train, y_train_one_hot)\nprint(\"Costo actual: (antes de optimizar)\", costo)\n# Le quité la creación de neuronas, por éso está comentado\n# print(\"Precisión antes de optimizar: \", precision(neuronas[L - 1], y_train))","execution_count":14,"outputs":[{"output_type":"stream","text":"[0.5488135  0.71518937 0.60276338 ... 0.60652939 0.69763688 0.66485748] (4075,)\nCosto actual: (antes de optimizar) 25.972441101074217\n","name":"stdout"}]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"res = op.minimize(\n    fun=funcion_costo,\n    x0=thetas,\n    args=(figuras, X_train, y_train_one_hot),\n    method='L-BFGS-B',\n    jac=back_propagation,\n    options={'disp': True, 'maxiter': 1300})\nres","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"      fun: 3.2507568359375\n hess_inv: <4075x4075 LbfgsInvHessProduct with dtype=float64>\n      jac: array([0.        , 0.        , 0.        , ..., 0.00174104, 0.00209646,\n       0.00217285])\n  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n     nfev: 26\n      nit: 5\n   status: 0\n  success: True\n        x: array([ 0.5488135 ,  0.71518937,  0.60276338, ..., -0.33199175,\n       -0.4993404 , -0.57803143])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"thetas = res.x\nprint(thetas)\ncosto = funcion_costo(thetas, figuras, X_train, y_train_one_hot)\n# Necesita las Thetas deschatadas\nthetas = deschatar_thetas(thetas, figuras)\nneuronas = forward_propagation(thetas, X_train)\nprint(costo)\nprint(precision(neuronas[L - 1], y_train))","execution_count":16,"outputs":[{"output_type":"stream","text":"[ 0.5488135   0.71518937  0.60276338 ... -0.33199175 -0.4993404\n -0.57803143]\n3.2507568359375\n0.1\n","name":"stdout"}]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"## Justificación de mi estructura de NN\n### ¿Por qué 5 capas ocultas y 5 neuronas?\nEn clase estuvimos discutiendo acerca del _Vanishing Gradient Problem_ , y que este se da al superar el número aproximado de 5. Es decir que con el modelo actual de la función Sigmoide tener más de 5 neuronas y 5 capas ocultas haría gradientes muy pequeños, que casi tienden a 0. \n\nAl ver los beneficios con pocas capas y con varias, 5 capas y 5 neuronas dieron un excelente resultado.\n\n### Resultados en el training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"unos = np.ones((len(X_test), 1)).astype(np.float32) ## agregar columna de unos\nneuronas = forward_propagation(thetas, X_test)\nprint(\"{} de precisión (sobre 100%) alcanzado en el testing set\".format(precision(neuronas[L - 1], y_test)))","execution_count":24,"outputs":[{"output_type":"stream","text":"0.1 de precisión (sobre 100%) alcanzado en el testing set\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}