{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion Mnist\n",
    "Fashion MNist es un dataset que contiene imágenes de ropa con fines académicos de aprender a crear un sistema de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales Completamente Conectadas\n",
    "Este es el sistema que usaremos para resolver el problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando las librerías\n",
    "from fashion_mnist_master.utils.mnist_reader import load_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as op\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importando la data\n",
    "X_train, y_train = load_mnist('fashion_mnist_master/data/fashion', kind='train')\n",
    "X_test, y_test = load_mnist('fashion_mnist_master/data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Gráficando un elemento \n",
    "X = np.array(X_train[1])\n",
    "X = X.reshape((28, 28))\n",
    "## Poniéndolo en blanco y negro\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(X, interpolation='nearest', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras ver la data por anticipado, se puede notar que existen valores entre 0 y 255 para identificar la intensidad de color de bits en la imagen. Debido a que los números están demasiado grandes. Por éso se procede a aplicarles una reducción a través de la variable _chiquitolina_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Transformación de X_train\n",
    "chiquitolina = (1/255) # Para achiquitar los valores\n",
    "X_train = X_train * (chiquitolina)\n",
    "X_train = X_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # Semilla de aleatoriedad constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## X_train tiene la siguiente forma\n",
    "### (observaciones, atributos)\n",
    "### Cada elemento del array es una observación. \n",
    "### Según mi documento oficial juandieguístico tiene la forma n*m\n",
    "L = 4 # Capas desde la X hasta la Y\n",
    "### One-hot enconding para Y\n",
    "y_train_one_hot = np.zeros((y_train.size, y_train.max()+1))\n",
    "y_train_one_hot[np.arange(y_train.size),y_train] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones propias de la Red Neuronal y capas de activación\n",
    "Las funciones que servirán como parámetros para la aplicación de _optimize_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCIONES IMPORTANTES\n",
    "def funcion_sigmoide(x, tetas):\n",
    "    \"\"\"Realiza la función sigmoide\n",
    "        para cualquier parámetro teta\n",
    "    \"\"\"\n",
    "    return np.power((1 + np.exp(-1 * np.dot(x, tetas.T)) ), -1).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_costo(tetas, figuras, x, y):\n",
    "    \"\"\"Realiza la función de costo\n",
    "        para cualquier parámetro teta\n",
    "    \"\"\"\n",
    "    tetas = deschatar_thetas(tetas, figuras)\n",
    "    neuronas = forward_propagation(tetas, x) # Multiplicación de tetas\n",
    "    return np.sum(np.multiply(y, np.log( neuronas[L-1] )) + np.multiply((1-y), np.log(1 - neuronas[L-1]))  ) / -len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_pred, y):\n",
    "    \"\"\"Calcula la precisión del modelo con base\n",
    "        a los valores reales y predichos de Y \n",
    "    \"\"\"\n",
    "    enconding = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        valorMax = max(y_pred[i])\n",
    "        valor = np.where(y_pred[i] == valorMax)\n",
    "        if(valor == y[i]):\n",
    "            enconding += 1 \n",
    "        \n",
    "    return enconding / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables de uso general para la red neuronal\n",
    "Aquí irán las neuronas, tamaño del modelo, constantes multiplicadoras y capa de _bias_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = []\n",
    "#### Cada elemento contiene un arreglo de thetas. \n",
    "####      Para el primero son c*m según el documento juandieguístico.\n",
    "#### Después serán 5*5 y el último será 10*6\n",
    "thetas1 = np.random.rand(5, 785) # X a capa1\n",
    "thetas2 = np.random.rand(5, 6) # capa1 a 2\n",
    "thetas3 = np.random.rand(5, 6) # capa2 a 3\n",
    "thetas4 = np.random.rand(10, 6) # capa3 a resultado\n",
    "## agregando thetas\n",
    "thetas.append(thetas1)\n",
    "thetas.append(thetas2)\n",
    "thetas.append(thetas3)\n",
    "thetas.append(thetas4)\n",
    "\n",
    "figuras = [(5, 785), (5, 6), (5, 6), (10, 6)]\n",
    "\n",
    "unos = np.ones((len(X_train), 1)).astype(np.float32) ## agregar columna de unos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de transformación de thetas para Scipy optimize\n",
    "Los multiplicadores deben de entregarse en un arreglo plano, por lo que hay funciones para aplanarlo y desaplanarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def achatar_thetas(tetas):\n",
    "    achatadas = np.array([])\n",
    "    for i in tetas:\n",
    "        achatadas = np.append(achatadas, i.flatten())\n",
    "    achatadas.flatten()\n",
    "    return achatadas\n",
    "\n",
    "def deschatar_thetas(tetas, figura):\n",
    "    deschatadas = []\n",
    "    inicio = 0\n",
    "    fin = 0\n",
    "    for i in figura:\n",
    "        fin = inicio + i[1]*i[0]\n",
    "        deschatadas.append(np.array(tetas[inicio:fin]).reshape(i))\n",
    "        inicio = fin\n",
    "    return deschatadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(tetas, x):\n",
    "    neuronas = [None] * L\n",
    "    neuronas[0] = x ## agregando la primera capa\n",
    "    for i in range(len(tetas)):\n",
    "        ###### La siguiente neurona\n",
    "        # print(i)\n",
    "        # print(neuronas[i].shape)\n",
    "        # print((np.append(neuronas[i], unos, axis=1)).shape)\n",
    "        # print(neuronas[i])\n",
    "        # capa_mas_bias = np.append(neuronas[i], unos, axis=1) # neurona actual más capa de unos (bias)\n",
    "        neuronas[i + 1] = funcion_sigmoide(\n",
    "            np.append(neuronas[i], unos, axis=1), tetas[i]) # Thetas actuales (ya incluyen la capa bias)\n",
    "    return neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(tetas, figuras, x, y):\n",
    "    tetas = deschatar_thetas(tetas, figuras)\n",
    "    # Back propagation\n",
    "    # Forward Propagation (Paso 2.2)\n",
    "    neuronas = forward_propagation(tetas, x)\n",
    "    # Paso 1 y 2.1\n",
    "    Deltas = [i * 0.0 for i in tetas]\n",
    "    deltas = [i * 0.0 for i in neuronas]\n",
    "    deltas[L - 1] = neuronas[L - 1] - y # Paso 2.3 del documento de Samuel Chávez\n",
    "    for l in reversed(range(0, L - 1)):\n",
    "        # Paso 2.4\n",
    "        deltas[l] = np.multiply(\n",
    "                np.dot(tetas[l].T[:-1], deltas[l + 1].T).T,\n",
    "                np.multiply(\n",
    "                    neuronas[l],\n",
    "                    (1 - neuronas[l])\n",
    "                    ))\n",
    "        \n",
    "        # Paso 2.5\n",
    "        Deltas[l] = Deltas[l] + np.dot(deltas[l + 1].T,\n",
    "                                       np.append(neuronas[l],\n",
    "                                                 unos, axis=1))\n",
    "        # Paso 3\n",
    "        Deltas[l] = Deltas[l] * (1/len(x))\n",
    "    return achatar_thetas(Deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación con Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5488135  0.71518937 0.60276338 ... 0.60652939 0.69763688 0.66485748] (4075,)\n",
      "Costo actual: (antes de optimizar) 25.972441101074217\n"
     ]
    }
   ],
   "source": [
    "thetas = achatar_thetas(thetas)\n",
    "print(thetas, thetas.shape)\n",
    "costo = funcion_costo(thetas, figuras, X_train, y_train_one_hot)\n",
    "print(\"Costo actual: (antes de optimizar)\", costo)\n",
    "# Le quité la creación de neuronas, por éso está comentado\n",
    "# print(\"Precisión antes de optimizar: \", precision(neuronas[L - 1], y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 3.2507568359375\n",
       " hess_inv: <4075x4075 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([0.        , 0.        , 0.        , ..., 0.00174104, 0.00209646,\n",
       "       0.00217285])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 26\n",
       "      nit: 5\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.5488135 ,  0.71518937,  0.60276338, ..., -0.33199175,\n",
       "       -0.4993404 , -0.57803143])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = op.minimize(\n",
    "    fun=funcion_costo,\n",
    "    x0=thetas,\n",
    "    args=(figuras, X_train, y_train_one_hot),\n",
    "    method='L-BFGS-B',\n",
    "    jac=back_propagation,\n",
    "    options={'disp': True, 'maxiter': 1300})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5488135   0.71518937  0.60276338 ... -0.33199175 -0.4993404\n",
      " -0.57803143]\n",
      "3.2507568359375\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "thetas = res.x\n",
    "print(thetas)\n",
    "costo = funcion_costo(thetas, figuras, X_train, y_train_one_hot)\n",
    "# Necesita las Thetas deschatadas\n",
    "thetas = deschatar_thetas(thetas, figuras)\n",
    "neuronas = forward_propagation(thetas, X_train)\n",
    "print(costo)\n",
    "print(precision(neuronas[L - 1], y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justificación de mi estructura de NN\n",
    "### ¿Por qué 5 capas ocultas y 5 neuronas?\n",
    "En clase estuvimos discutiendo acerca del _Vanishing Gradient Problem_ , y que este se da al superar el número aproximado de 5. Es decir que con el modelo actual de la función Sigmoide tener más de 5 neuronas y 5 capas ocultas haría gradientes muy pequeños, que casi tienden a 0. \n",
    "\n",
    "Al ver los beneficios con pocas capas y con varias, 5 capas y 5 neuronas dieron un excelente resultado.\n",
    "\n",
    "### Resultados en el training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 de precisión (sobre 100%) alcanzado en el testing set\n"
     ]
    }
   ],
   "source": [
    "unos = np.ones((len(X_test), 1)).astype(np.float32) ## agregar columna de unos\n",
    "neuronas = forward_propagation(thetas, X_test)\n",
    "print(\"{} de precisión (sobre 100%) alcanzado en el testing set\".format(precision(neuronas[L - 1], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
