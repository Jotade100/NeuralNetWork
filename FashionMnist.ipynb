{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion Mnist\n",
    "Fashion MNist es un dataset que contiene imágenes de ropa con fines académicos de aprender a crear un sistema de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales Completamente Conectadas\n",
    "Este es el sistema que usaremos para resolver el problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando las librerías\n",
    "from fashion_mnist_master.utils.mnist_reader import load_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as op\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importando la data\n",
    "X_train, y_train = load_mnist('fashion_mnist_master/data/fashion', kind='train')\n",
    "X_test, y_test = load_mnist('fashion_mnist_master/data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Gráficando un elemento \n",
    "X = np.array(X_train[1])\n",
    "X = X.reshape((28, 28))\n",
    "## Poniéndolo en blanco y negro\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(X, interpolation='nearest', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras ver la data por anticipado, se puede notar que existen valores entre 0 y 255 para identificar la intensidad de color de bits en la imagen. Debido a que los números están demasiado grandes. Por éso se procede a aplicarles una reducción a través de la variable _chiquitolina_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Transformación de X_train\n",
    "chiquitolina = (1/1) # Para achiquitar los valores\n",
    "X_train = X_train[0:10000] * (chiquitolina)\n",
    "X_train = X_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Semilla de aleatoriedad constante\n",
    "np.seterr(divide = 'ignore')  # Por log(0) que sabemos es -inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## X_train tiene la siguiente forma\n",
    "### (observaciones, atributos)\n",
    "### Cada elemento del array es una observación. \n",
    "### Según mi documento oficial juandieguístico tiene la forma n*m\n",
    "L = 4 # Capas desde la X hasta la Y\n",
    "### One-hot enconding para Y\n",
    "y_train = y_train[0:10000]\n",
    "y_train_one_hot = np.zeros((y_train.size, y_train.max()+1))\n",
    "y_train_one_hot[np.arange(y_train.size),y_train] = 1\n",
    "y_solver = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones propias de la Red Neuronal y capas de activación\n",
    "Las funciones que servirán como parámetros para la aplicación de _optimize_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCIONES IMPORTANTES\n",
    "def funcion_sigmoide(x, tetas):\n",
    "    \"\"\"Realiza la función sigmoide\n",
    "        para cualquier parámetro teta\n",
    "    \"\"\"\n",
    "    return np.power((1 + np.exp(-1 * np.dot(x, tetas.T)) ), -1).astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de costo usada para multiclase\n",
    "$$\n",
    "E_{-x} = - \\sum_{k}[t_k^x \\log(o_k^x) + (1-t_k^x) \\log (1- o_k^x)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_costo(tetas, figuras, x, y):\n",
    "    \"\"\"Realiza la función de costo\n",
    "        para cualquier parámetro teta\n",
    "    \"\"\"\n",
    "    tetas = deschatar_thetas(tetas, figuras)\n",
    "    neuronas = forward_propagation(tetas, x) # Multiplicación de tetas\n",
    "    return np.sum(np.multiply(y, np.log( neuronas[L-1] )) + np.multiply((1-y), np.log(1 - neuronas[L-1]))  ) / -len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_pred, y):\n",
    "    \"\"\"Calcula la precisión del modelo con base\n",
    "        a los valores reales y predichos de Y \n",
    "    \"\"\"\n",
    "    enconding = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        valor = np.argmax(y_pred[i])\n",
    "        if(valor == y[i]):\n",
    "            enconding += 1 \n",
    "        \n",
    "    return enconding / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_costo_base_precision(tetas, figuras, x, y):\n",
    "    \"\"\"Realiza la función de costo\n",
    "        para cualquier parámetro teta\n",
    "    \"\"\"\n",
    "    tetas = deschatar_thetas(tetas, figuras)\n",
    "    neuronas = forward_propagation(tetas, x) # Multiplicación de tetas\n",
    "    y_label = np.dot(y, y_solver)\n",
    "    return 1/(precision(neuronas[L-1], y_label))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables de uso general para la red neuronal\n",
    "Aquí irán las neuronas, tamaño del modelo, constantes multiplicadoras y capa de _bias_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = []\n",
    "#### Cada elemento contiene un arreglo de thetas. \n",
    "####      Para el primero son c*m según el documento juandieguístico.\n",
    "#### Después serán 5*5 y el último será 10*6\n",
    "thetas1 = np.random.rand(100, 785) # X a capa1\n",
    "thetas2 = np.random.rand(50, 101) # capa1 a 2\n",
    "thetas3 = np.random.rand(10, 51) # capa2 a resultado\n",
    "## agregando thetas\n",
    "thetas.append(thetas1)\n",
    "thetas.append(thetas2)\n",
    "thetas.append(thetas3)\n",
    "\n",
    "figuras = [(100, 785), (50, 101), (10, 51)]\n",
    "\n",
    "unos = np.ones((len(X_train), 1)).astype(np.float32) ## agregar columna de unos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de transformación de thetas para Scipy optimize\n",
    "Los multiplicadores deben de entregarse en un arreglo plano, por lo que hay funciones para aplanarlo y desaplanarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def achatar_thetas(tetas):\n",
    "    achatadas = np.array([])\n",
    "    for i in tetas:\n",
    "        achatadas = np.append(achatadas, i.flatten())\n",
    "    achatadas.flatten()\n",
    "    return achatadas\n",
    "\n",
    "def deschatar_thetas(tetas, figura):\n",
    "    deschatadas = []\n",
    "    inicio = 0\n",
    "    fin = 0\n",
    "    for i in figura:\n",
    "        fin = inicio + i[1]*i[0]\n",
    "        deschatadas.append(np.array(tetas[inicio:fin]).reshape(i))\n",
    "        inicio = fin\n",
    "    return deschatadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(tetas, x):\n",
    "    neuronas = [None] * L\n",
    "    neuronas[0] = x ## agregando la primera capa\n",
    "    for i in range(len(tetas)):\n",
    "        ###### La siguiente neurona\n",
    "        # print(i)\n",
    "        # print(neuronas[i].shape)\n",
    "        # print((np.append(neuronas[i], unos, axis=1)).shape)\n",
    "        # print(neuronas[i])\n",
    "        # capa_mas_bias = np.append(neuronas[i], unos, axis=1) # neurona actual más capa de unos (bias)\n",
    "        neuronas[i + 1] = funcion_sigmoide(\n",
    "            np.append(neuronas[i], unos, axis=1), tetas[i]) # Thetas actuales (ya incluyen la capa bias)\n",
    "    return neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(tetas, figuras, x, y):\n",
    "    tetas = deschatar_thetas(tetas, figuras)\n",
    "    # Back propagation\n",
    "    # Forward Propagation (Paso 2.2)\n",
    "    neuronas = forward_propagation(tetas, x)\n",
    "    # Paso 1 y 2.1\n",
    "    Deltas = [i * 0.0 for i in tetas]\n",
    "    deltas = [i * 0.0 for i in neuronas]\n",
    "    deltas[L - 1] = neuronas[L - 1] - y # Paso 2.3 del documento de Samuel Chávez\n",
    "    for l in reversed(range(0, L - 1)):\n",
    "        # Paso 2.4\n",
    "        deltas[l] = np.multiply(\n",
    "                np.dot(tetas[l].T[:-1], deltas[l + 1].T).T,\n",
    "                np.multiply(\n",
    "                    neuronas[l],\n",
    "                    (1 - neuronas[l])\n",
    "                    ))\n",
    "        \n",
    "        # Paso 2.5\n",
    "        Deltas[l] = Deltas[l] + np.dot(deltas[l + 1].T,\n",
    "                                       np.append(neuronas[l],\n",
    "                                                 unos, axis=1))\n",
    "        # Paso 3\n",
    "        Deltas[l] = Deltas[l] * (1/len(x))\n",
    "    return achatar_thetas(Deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación con Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5488135  0.71518937 0.60276338 ... 0.46419364 0.04709377 0.17385815] (84060,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\juan diego\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in multiply\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costo actual: (antes de optimizar) nan\n",
      "Precisión antes de optimizar:  0.0942\n"
     ]
    }
   ],
   "source": [
    "thetas = achatar_thetas(thetas)\n",
    "print(thetas, thetas.shape)\n",
    "costo = funcion_costo(thetas, figuras, X_train, y_train_one_hot)\n",
    "print(\"Costo actual: (antes de optimizar)\", costo)\n",
    "# Le quité la creación de neuronas, por éso está comentado\n",
    "thetas = deschatar_thetas(thetas, figuras)\n",
    "neuronas = forward_propagation(thetas, X_train)\n",
    "print(\"Precisión antes de optimizar: \", precision(neuronas[L - 1], y_train))\n",
    "thetas = achatar_thetas(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\juan diego\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in multiply\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: 3.2500903076171874\n",
       " hess_inv: <84060x84060 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ 0.        ,  0.        ,  0.        , ..., -0.00020752,\n",
       "       -0.00020752, -0.00020752])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 35\n",
       "      nit: 10\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.5488135 ,  0.71518937,  0.60276338, ..., -0.05927228,\n",
       "       -0.47637216, -0.34960777])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = op.minimize(\n",
    "    fun=funcion_costo,\n",
    "    x0=thetas,\n",
    "    args=(figuras, X_train, y_train_one_hot),\n",
    "    method='L-BFGS-B',\n",
    "    jac=back_propagation,\n",
    "    options={'disp': True, 'maxiter': 1300})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5488135   0.71518937  0.60276338 ... -0.05927228 -0.47637216\n",
      " -0.34960777]\n",
      "3.2500903076171874\n",
      "0.1027\n"
     ]
    }
   ],
   "source": [
    "thetas = res.x\n",
    "print(thetas)\n",
    "costo = funcion_costo(thetas, figuras, X_train, y_train_one_hot)\n",
    "# Necesita las Thetas deschatadas\n",
    "thetas = deschatar_thetas(thetas, figuras)\n",
    "neuronas = forward_propagation(thetas, X_train)\n",
    "print(costo)\n",
    "print(precision(neuronas[L - 1], y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justificación de mi estructura de NN\n",
    "### ¿Por qué 4 capas ocultas y 5 neuronas?\n",
    "En clase estuvimos discutiendo acerca del _Vanishing Gradient Problem_ , y que este se da al superar el número aproximado de 5. Es decir que con el modelo actual de la función Sigmoide tener más de 5 neuronas y 5 capas ocultas haría gradientes muy pequeños, que casi tienden a 0. \n",
    "\n",
    "Al ver los beneficios con pocas capas y con varias, 5 capas y 5 neuronas dieron un excelente resultado.\n",
    "\n",
    "### Resultados en el training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 de precisión (sobre 100%) alcanzado en el testing set\n"
     ]
    }
   ],
   "source": [
    "unos = np.ones((len(X_test), 1)).astype(np.float32) ## agregar columna de unos\n",
    "neuronas = forward_propagation(thetas, X_test)\n",
    "print(\"{} de precisión (sobre 100%) alcanzado en el testing set\".format(precision(neuronas[L - 1], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
